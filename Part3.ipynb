{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/vy/5s7czd7x62g2zzft4svx687w0000gn/T/tmpyxjvj_1s/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73892"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"將tensorflow檔轉成tensorflow lite，使機器負載量變小\"\"\"\n",
    "from tensorflow import lite\n",
    "from tensorflow.keras import models\n",
    "\n",
    "# Parameters\n",
    "keras_model_filename = '/Users/Willie/Test1.h5' #訓練好的模型\n",
    "tflite_filename = '/Users/Willie/Test1.tflite' #預建置檔案\n",
    "\n",
    "# Convert model to TF Lite model\n",
    "model = models.load_model(keras_model_filename) #載入本來的模型\n",
    "converter = lite.TFLiteConverter.from_keras_model(model) #將模型載入轉換器\n",
    "tflite_model = converter.convert() #進行轉換\n",
    "open(tflite_filename, 'wb').write(tflite_model) #輸出轉換後的模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "的一個\n",
      "MAX:0.9882245063781738\n",
      "0時0分0秒\n",
      "著\n",
      "MAX:0.5345511436462402\n",
      "0時0分1秒\n",
      "著\n",
      "MAX:0.6017727851867676\n",
      "0時0分2秒\n",
      "的一個\n",
      "MAX:0.669132649898529\n",
      "0時0分2秒\n",
      "的一個\n",
      "MAX:0.9548832178115845\n",
      "0時0分3秒\n",
      "的一個\n",
      "MAX:0.7477481961250305\n",
      "0時0分3秒\n",
      "的一個\n",
      "MAX:0.6256881356239319\n",
      "0時0分4秒\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import timeit\n",
    "import python_speech_features\n",
    "import tensorflow as tf\n",
    "from PyQt5.QtCore import QTime\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#import RPi.GPIO as GPIO\n",
    "\n",
    "# Parameters\n",
    "debug_time = 0 #Debug用\n",
    "debug_acc = 1 #Debug用\n",
    "led_pin = 8 #LED PIN\n",
    "word_threshold = 0.5 #預測值>0.5，表示stop\n",
    "rec_duration = 0.5 #每一段錄音持續時間\n",
    "#window_stride = 0.5\n",
    "sample_rate = 48000 #取樣率(依MIC不同而改變)\n",
    "resample_rate = 8000 #重整後的取樣率(符合MODEL)\n",
    "num_channels = 1 #音訊深度\n",
    "num_mfcc = 16 #回傳mfcc的量\n",
    "model_path = '/Users/Willie/Test1.tflite'\n",
    "words = ['ㄏㄧㄡ','ㄟ','吼','啦','嗯','的一個','的這個','的那個','著','那','那那個','阿']#答案對應到的字詞\n",
    "s = 0 #秒\n",
    "m = 0 #分\n",
    "h = 0 #時\n",
    "\n",
    "# Sliding window\n",
    "window = np.zeros(int(rec_duration * resample_rate) * 2)#取樣音頻數據變數\n",
    "\n",
    "# GPIO \n",
    "#GPIO.setwarnings(False)\n",
    "#GPIO.setmode(GPIO.BOARD)\n",
    "#GPIO.setup(8, GPIO.OUT, initial=GPIO.LOW)\n",
    "\n",
    "# Load model (interpreter)\n",
    "interpreter = tf.lite.Interpreter(model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "#開始計時\n",
    "counter = QTime()\n",
    "counter.restart()\n",
    "\n",
    "# Decimate (filter and downsample)\n",
    "def decimate(signal, old_fs, new_fs):\n",
    "    \n",
    "    #檢查是否降低音頻\n",
    "    if new_fs > old_fs:\n",
    "        print(\"Error: target sample rate higher than original\")\n",
    "        return signal, old_fs\n",
    "    \n",
    "    #檢查是否為整數(只能在整數下執行)\n",
    "    dec_factor = old_fs / new_fs\n",
    "    if not dec_factor.is_integer():\n",
    "        print(\"Error: can only decimate by integer factor\")\n",
    "        return signal, old_fs\n",
    "\n",
    "    # Do decimation\n",
    "    resampled_signal = scipy.signal.decimate(signal, int(dec_factor))\n",
    "\n",
    "    return resampled_signal, new_fs\n",
    "\n",
    "# This gets called every 0.5 seconds\n",
    "def sd_callback(rec, frames, time, status):\n",
    "\n",
    "    #GPIO.output(led_pin, GPIO.LOW)\n",
    "    \n",
    "    # Notify if errors\n",
    "    if status:\n",
    "        print('Error:', status)\n",
    "    \n",
    "    # Remove 2nd dimension from recording sample\n",
    "    #壓縮成1D張量\n",
    "    rec = np.squeeze(rec)\n",
    "    \n",
    "    # Resample\n",
    "    #重取樣成8000HZ(以符合訓練模型)\n",
    "    rec, new_fs = decimate(rec, sample_rate, resample_rate)\n",
    "    \n",
    "    # Save recording onto sliding window\n",
    "    #將音訊輸入到window\n",
    "    window[:len(window)//2] = window[len(window)//2:]\n",
    "    window[len(window)//2:] = rec\n",
    "\n",
    "    # Compute features\n",
    "    mfccs = python_speech_features.base.mfcc(window, #輸入訊號\n",
    "                                        samplerate=new_fs, #取樣率\n",
    "                                        winlen=0.256, #音框涵蓋時間\n",
    "                                        winstep=0.050, #音框間距離\n",
    "                                        numcep=num_mfcc, #返回係數的量\n",
    "                                        nfilt=26, #過濾器數量\n",
    "                                        nfft=2048,#FFT大小\n",
    "                                        preemph=0.0,#不用預強化濾波器\n",
    "                                        ceplifter=0,#ROBUST\n",
    "                                        appendEnergy=False,#係數0的話對被替代成總音框能量的對數\n",
    "                                        winfunc=np.hanning)#hanning window\n",
    "    mfccs = mfccs.transpose()\n",
    "\n",
    "    # Make prediction from model\n",
    "    in_tensor = np.float32(mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1))\n",
    "    #設定輸入張量\n",
    "    interpreter.set_tensor(input_details[0]['index'], in_tensor)\n",
    "    #進行預測\n",
    "    interpreter.invoke()\n",
    "    #取得輸出張量\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    val = output_data[0]#取得預測值\n",
    "    val = val.tolist() #np.ndarray to list\n",
    "    list_val_max = max(val) #取得最大值\n",
    "    list_val_maxIndex = val.index(max(val)) #取得最大值的索引  \n",
    "    \n",
    "    if(list_val_max >= 0.5 and words[list_val_maxIndex] != 'ㄟ' \n",
    "       and words[list_val_maxIndex] != '阿' and words[list_val_maxIndex] != '嗯' ):#如果預測值>=0.3、嗯、阿、ㄟ拿掉\n",
    "        print(words[list_val_maxIndex])#輸出相對應的字詞\n",
    "        print(\"MAX:\" + str(list_val_max))#輸出預測值當中最大的值\n",
    "        print(str(h) + \"時\" + str(m) + \"分\"+str(s)+\"秒\")\n",
    "        #print(str(h) + \"時\" + str(m) + \"分\"+\"{:.1f}秒\".format(s))\n",
    "    #if debug_acc:\n",
    "    #    print(\"pred:\" + str(val))#輸出所有預測值\n",
    "    #    print(\"MAX:\" + str(list_val_max))#輸出預測值當中最大的值\n",
    "    #    print(\"MAX_INDEX:\" + str(list_val_maxIndex))#輸出最大值的索引值\n",
    "\n",
    "\n",
    "# Start streaming from microphone\n",
    "with sd.InputStream(channels=num_channels,\n",
    "                    samplerate=sample_rate,\n",
    "                    blocksize=int(sample_rate * rec_duration),\n",
    "                    callback=sd_callback):\n",
    "    while True:\n",
    "        s = int(counter.elapsed() / 1000)\n",
    "        if(s == 60):\n",
    "            counter.restart()\n",
    "            s = 0\n",
    "            m +=1\n",
    "        if(m == 60):\n",
    "            m = 0\n",
    "            h +=1\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
